{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-of-words representation\n",
    "---\n",
    "\n",
    "Goal: Represent texts as a vector of numbers for our ML tasks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We cannot use X: ML models work with numerical features!\n",
    "X = [\n",
    "    \"Scikit-learn makes ML easy, easy as 123\", \n",
    "    \"Learning TensorFlow for deep learning\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: Create a feature for each word with the number of times the word appears as its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Scikit-learn provides a vectorizer transformer for that\n",
    "vect = CountVectorizer()\n",
    "X_encoded = vect.fit_transform(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print vocabulary (the features) with their column index in the feature matrix\n",
    "for word, index in vect.vocabulary_.items():\n",
    "    print('\"{}\" with index {}'.format(word, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input size\n",
    "X_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In practice, this approach usually leads to a large number of features (words) and only a few non-zero values per entry. For this reason, Scikit-learn stores the data as a \"sparse matrix\" that only stores non-zero values which is more memory efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn uses sparse matrices instead of Numpy arrays\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can always get back the data as Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "* `X_encoded[0, 3]` is 2 because \"easy\" (with index 3) appears twice in the first entry\n",
    "* `X_encoded[1, 6]` is 2 because \"learning\" with index 6 appears twice in the second entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concrete use case - Sentiment analysis\n",
    "---\n",
    "\n",
    "Task: Classify movie reviews as being `positive` or `negative` about their movie. This is a binary classification task with text input.\n",
    "\n",
    "Download the `Large Movie Review Dataset v1.0 ` data from https://ai.stanford.edu/~amaas/data/sentiment/ and extract it in a `aclImdb` folder next to this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import os\n",
    "\n",
    "# Train set\n",
    "train_data = load_files(os.path.join('aclImdb', 'train'), categories=['pos', 'neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First review\n",
    "train_data.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes\n",
    "train_data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.target[0] # \"positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X, y arrays\n",
    "vect = CountVectorizer()\n",
    "y = train_data.target\n",
    "X = train_data.data\n",
    "X_encoded = vect.fit_transform(X)\n",
    "\n",
    "# Vocabulary and input\n",
    "print('Training size:', len(train_data.data))\n",
    "print('Vocabulary size:', len(vect.vocabulary_))\n",
    "print('Input shape:', X_encoded.shape)\n",
    "print('Target shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Use logistic regression to classify reviews\n",
    "grid_cv = GridSearchCV(\n",
    "    estimator=LogisticRegression(solver='liblinear'),\n",
    "    param_grid={\n",
    "        'C': [0.1, 1, 10]\n",
    "    },\n",
    "    cv=3,\n",
    "    return_train_score=True\n",
    ")\n",
    "grid_cv.fit(X_encoded, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Collect results in a DataFrame\n",
    "cv_results = pd.DataFrame(grid_cv.cv_results_)\n",
    "cols = ['param_C', 'mean_test_score', 'std_test_score', 'mean_train_score', 'std_train_score']\n",
    "cv_results[cols].sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variants\n",
    "---\n",
    "\n",
    "There are also slightly more sophisticated methods like TD-IDF which normalizes counts by popularity of the word - the idea is that words that appear in many entries are less relevant to solve our task. A common example are stopwords like \"the\", \"is\", \"a\" but common words might also be specific to our data set ex. \"movie\", \"actor\" are common words in our case and irrelevant to classify the review as positive or negative.\n",
    "\n",
    "In addition to logistic regressions, the Naive Bayes classifier is another baseline to evaluate when working with texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create a pipeline this time\n",
    "pipe = Pipeline([\n",
    "    ('vect', None),\n",
    "    ('clf', None)\n",
    "])\n",
    "\n",
    "# Try with simple counts and TF-IDF / Logistic regressions and Naive Bayes\n",
    "grid_cv = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid={\n",
    "        'vect': [CountVectorizer(), TfidfVectorizer()],\n",
    "        'clf': [LogisticRegression(solver='liblinear'), MultinomialNB()]\n",
    "    },\n",
    "    cv=3,\n",
    "    return_train_score=True,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "grid_cv.fit(X, y)\n",
    "\n",
    "# Collect results in a DataFrame\n",
    "cv_results = pd.DataFrame({\n",
    "    'clf': [type(clf).__name__ for clf in grid_cv.cv_results_['param_clf']],\n",
    "    'vect': [type(clf).__name__ for clf in grid_cv.cv_results_['param_vect']],\n",
    "    'mean_test_score': grid_cv.cv_results_['mean_test_score'],\n",
    "    'std_test_score': grid_cv.cv_results_['std_test_score'],\n",
    "    'mean_train_score': grid_cv.cv_results_['mean_train_score'],\n",
    "    'std_train_score': grid_cv.cv_results_['std_train_score']\n",
    "})\n",
    "cv_results.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final test evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_files(os.path.join('aclImdb', 'test'), categories=['pos', 'neg'])\n",
    "grid_cv.score(test_data.data, test_data.target) # Score best estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional ressources\n",
    "---\n",
    "\n",
    "Scikit-learn provides many options for vectorizers, make sure to check the [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) and [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) documentations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
