{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bike sharing model evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: Load train/test sets\n",
    "---\n",
    "\n",
    "> **Exercise**: Load the train/test sets into the `train_df`/`test_df` DataFrames. Create the x/y Numpy arrays from the `temp` and `users` columns. Plot the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data sets\n",
    "train_df = pd.read_csv(os.path.join('data', 'bike-train.csv'))\n",
    "test_df = pd.read_csv(os.path.join('data', 'bike-test.csv'))\n",
    "\n",
    "# Create x/y Numpy arrays\n",
    "x_tr = train_df.temp.values\n",
    "y_tr = train_df.users.values\n",
    "\n",
    "x_te = test_df.temp.values\n",
    "y_te = test_df.users.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data points\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(x_tr, y_tr, label='train', s=10)\n",
    "plt.scatter(x_te, y_te, label='test', s=10)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: Fit and compare different models\n",
    "---\n",
    "\n",
    "> **Exercise**: (A) Fit several models to the train data and evaluate their performance on the test set using MAE. (B) Remove the outliers with the z-scores. (C) Create a baseline model and do a final model comparison using a bar chart.\n",
    "\n",
    "Some ideas: Linear regression, polyfit with different degrees, linear regression with Huber loss, linear regression without outliers, polyfit without outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MAE cost function\n",
    "def MAE(y, y_pred):\n",
    "    return np.mean(np.abs(y - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# (A) Test different models\n",
    "# * Linear regression\n",
    "coefs_lr = np.polyfit(x_tr, y_tr, deg=1) # Fit to train data\n",
    "y_pred_lr = np.polyval(coefs_lr, x_te) # Predictions for test data points\n",
    "mae_lr = MAE(y_te, y_pred_lr) # MAE of predictions\n",
    "# Print performance on test set\n",
    "print('MAE linear regression: {:.3f}'.format(mae_lr))\n",
    "\n",
    "# * Polyfit with degree 3\n",
    "coefs_poly3 = np.polyfit(x_tr, y_tr, deg=3) # Fit to train data\n",
    "y_pred_poly3 = np.polyval(coefs_poly3, x_te) # Predictions for test data points\n",
    "mae_poly3 = MAE(y_te, y_pred_poly3) # MAE of predictions\n",
    "print('MAE polyfit(deg=3): {:.3f}'.format(mae_poly3))\n",
    "\n",
    "# * Huber loss\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "huber = HuberRegressor(epsilon=1.1) # Create object\n",
    "huber.fit(x_tr[:, np.newaxis], y_tr) # Fit it to train data\n",
    "y_pred_huber = huber.predict(x_te[:, np.newaxis]) # Predictions for test data points\n",
    "mae_huber = MAE(y_te, y_pred_huber) # MAE of predictions\n",
    "print('MAE Huber: {:.3f}'.format(mae_huber))\n",
    "\n",
    "# Plot the prediction curves\n",
    "# Generate a hundred points\n",
    "x_values = np.linspace(min(x_te), max(x_te), num=100)\n",
    "\n",
    "# and the predictions\n",
    "y_values_lr = np.polyval(coefs_lr, x_values)\n",
    "y_values_poly3 = np.polyval(coefs_poly3, x_values)\n",
    "y_values_huber = huber.predict(x_values[:, np.newaxis])\n",
    "\n",
    "# Plot them\n",
    "plt.scatter(x_te, y_te, s=10)\n",
    "plt.plot(x_values, y_values_lr, label='linear regression')\n",
    "plt.plot(x_values, y_values_poly3, label='polyfit(deg=3)')\n",
    "plt.plot(x_values, y_values_huber, label='Huber loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (B) Remove outliers\n",
    "# Compute z-scores\n",
    "z_scores = (y_tr - np.mean(y_tr)) / np.std(y_tr)\n",
    "\n",
    "# Plot them\n",
    "plt.scatter(x_tr, y_tr, c=z_scores, cmap=plt.cm.coolwarm)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Detect \"extreme\" data points\n",
    "# 2 standard deviations away form the mean\n",
    "idx = np.abs(z_scores) < 2 \n",
    "\n",
    "# Remove them\n",
    "x_tr2, y_tr2 = x_tr[idx], y_tr[idx]\n",
    "\n",
    "# Plot the remaining points\n",
    "plt.scatter(x_tr2, y_tr2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression without outliers\n",
    "coefs_lr2 = np.polyfit(x_tr2, y_tr2, deg=1) # Fit to train data without outliers\n",
    "y_pred_lr2 = np.polyval(coefs_lr2, x_te) # Predictions for test data points\n",
    "mae_lr2 = MAE(y_te, y_pred_lr2) # MAE of predictions\n",
    "print('MAE linear regression 2: {:.3f}'.format(mae_lr2))\n",
    "\n",
    "# Polyfit with degree 3\n",
    "coefs_poly3_2 = np.polyfit(x_tr2, y_tr2, deg=3) # Fit to train data without outliers\n",
    "y_pred_poly3_2 = np.polyval(coefs_poly3_2, x_te) # Predictions for test data points\n",
    "mae_poly3_2 = MAE(y_te, y_pred_poly3_2) # MAE of predictions\n",
    "print('MAE polyfit(deg=3) 2: {:.3f}'.format(mae_poly3_2))\n",
    "\n",
    "# Predictions for the hundred x_values\n",
    "y_values_lr2 = np.polyval(coefs_lr2, x_values)\n",
    "y_values_poly3_2 = np.polyval(coefs_poly3_2, x_values)\n",
    "\n",
    "# Plot all models\n",
    "plt.scatter(x_te, y_te, s=10)\n",
    "plt.plot(x_values, y_values_lr, label='linear regression')\n",
    "plt.plot(x_values, y_values_lr2, label='linear regression without outliers')\n",
    "plt.plot(x_values, y_values_huber, label='huber loss')\n",
    "plt.plot(x_values, y_values_poly3, label='polyfit(deg=3)')\n",
    "plt.plot(x_values, y_values_poly3_2, label='polyfit(deg=3) without outliers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (C) Final comparison\n",
    "# Baseline\n",
    "mae_baseline = MAE(y_te, np.median(y_tr))\n",
    "\n",
    "# Bar plot\n",
    "mae_values = [mae_baseline, mae_lr, mae_poly3, mae_huber, mae_lr2, mae_poly3_2]\n",
    "titles = ['median', 'lr', 'poly3', 'huber', 'lr2', 'poly3_2']\n",
    "\n",
    "xcor = np.arange(len(mae_values))\n",
    "plt.bar(xcor, mae_values)\n",
    "plt.xticks(xcor, titles)\n",
    "\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
