{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "provincial-sailing",
   "metadata": {},
   "source": [
    "#  Pandas string functions\n",
    "You might wonder, why we need to bother with string functions from pandas and not just use the Python standard ones? The reason is that Python's string functions are for individual string objects, while the pandas functions are for Series and DataFrames. So you can think of the pandas string functions as an extension that allows us to operate on an entire Series or DataFrame of strings. As most of the time, the text data that we will be working with will already be in the form of a Series or a DataFrame, so using the specific functions from pandas will make our life a lot easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distinct-concord",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              0\n",
       "1      John Wood\n",
       "2    Colin Welsh\n",
       "3        my list\n",
       "4          02456\n",
       "5            NaN\n",
       "6    HELLO WORLD\n",
       "7         water%\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s=pd.Series(['0', 'John Wood', 'Colin Welsh', 'my list', '02456', np.nan, 'HELLO WORLD', 'water%'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "american-adapter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              0\n",
       "1      john wood\n",
       "2    colin welsh\n",
       "3        my list\n",
       "4          02456\n",
       "5            NaN\n",
       "6    hello world\n",
       "7         water%\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "solar-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              0\n",
       "1      JOHN WOOD\n",
       "2    COLIN WELSH\n",
       "3        MY LIST\n",
       "4          02456\n",
       "5            NaN\n",
       "6    HELLO WORLD\n",
       "7         WATER%\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "disciplinary-florida",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.0\n",
       "1     9.0\n",
       "2    11.0\n",
       "3     7.0\n",
       "4     5.0\n",
       "5     NaN\n",
       "6    11.0\n",
       "7     6.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inner-mitchell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               [0]\n",
       "1      [John, Wood]\n",
       "2    [Colin, Welsh]\n",
       "3        [my, list]\n",
       "4           [02456]\n",
       "5               NaN\n",
       "6    [HELLO, WORLD]\n",
       "7          [water%]\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "elder-offering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>Wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Colin</td>\n",
       "      <td>Welsh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my</td>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02456</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HELLO</td>\n",
       "      <td>WORLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>water%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1\n",
       "0       0   None\n",
       "1    John   Wood\n",
       "2   Colin  Welsh\n",
       "3      my   list\n",
       "4   02456   None\n",
       "5     NaN    NaN\n",
       "6   HELLO  WORLD\n",
       "7  water%   None"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substrings = s.str.split(' ', expand=True)\n",
    "substrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fifteen-wichita",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     Wood\n",
       "2    Welsh\n",
       "3     list\n",
       "4     None\n",
       "5      NaN\n",
       "6    WORLD\n",
       "7     None\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substrings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lucky-toolbox",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              0\n",
       "1      John Wood\n",
       "2    Colin Welsh\n",
       "3        my list\n",
       "4          02456\n",
       "5            NaN\n",
       "6    HELLO WORLD\n",
       "7         water%\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.replace('strA','strB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "demographic-elder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 0\n",
       "1         John Wood\n",
       "2       Colin Welsh\n",
       "3           my list\n",
       "4             02456\n",
       "5               NaN\n",
       "6       HELLO WORLD\n",
       "7    water percent \n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.replace('%',' percent ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aggregate-evaluation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              0\n",
       "1      John Wood\n",
       "2    Colin Welsh\n",
       "3        my list\n",
       "4          02456\n",
       "5            NaN\n",
       "6    HELLO WORLD\n",
       "7          water\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.replace('%','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "verbal-turkish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1     Jo\n",
       "2     Co\n",
       "3     my\n",
       "4     02\n",
       "5    NaN\n",
       "6     HE\n",
       "7     wa\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cosmetic-herald",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1     Jo\n",
       "2     Co\n",
       "3     my\n",
       "4     02\n",
       "5    NaN\n",
       "6     HE\n",
       "7     wa\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.slice(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "demonstrated-restaurant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             ___\n",
       "1      ___hn Wood\n",
       "2    ___lin Welsh\n",
       "3        ___ list\n",
       "4          ___456\n",
       "5             NaN\n",
       "6    ___LLO WORLD\n",
       "7         ___ter%\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# str.slice_replace(i,j,'str')\n",
    "\n",
    "s.str.slice_replace(0,2, '___')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "double-hardware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4     True\n",
       "5      NaN\n",
       "6    False\n",
       "7    False\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag = s.str.contains('0')\n",
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "together-absorption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4     True\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag = s.str.contains('0', na=False)\n",
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "distant-evans",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "4    02456\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[flag]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-utility",
   "metadata": {},
   "source": [
    "# Cleaning up the movies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "weighted-device",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>http://www.thedarkknightrises.com/</td>\n",
       "      <td>49026</td>\n",
       "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "      <td>112.312950</td>\n",
       "      <td>[{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>1084939099</td>\n",
       "      <td>165.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Legend Ends</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://movies.disney.com/john-carter</td>\n",
       "      <td>49529</td>\n",
       "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "      <td>43.926995</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-03-07</td>\n",
       "      <td>284139100</td>\n",
       "      <td>132.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Lost in our world, found in another.</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget                                             genres  \\\n",
       "0  237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1  300000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "2  245000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "3  250000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "4  260000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "\n",
       "                                       homepage      id  \\\n",
       "0                   http://www.avatarmovie.com/   19995   \n",
       "1  http://disney.go.com/disneypictures/pirates/     285   \n",
       "2   http://www.sonypictures.com/movies/spectre/  206647   \n",
       "3            http://www.thedarkknightrises.com/   49026   \n",
       "4          http://movies.disney.com/john-carter   49529   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
       "1  [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...                en   \n",
       "2  [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...                en   \n",
       "3  [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...                en   \n",
       "4  [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...                en   \n",
       "\n",
       "                             original_title  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "3                     The Dark Knight Rises   \n",
       "4                               John Carter   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "1  Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
       "2  A cryptic message from Bond’s past sends him o...  107.376788   \n",
       "3  Following the death of District Attorney Harve...  112.312950   \n",
       "4  John Carter is a war-weary, former military ca...   43.926995   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
       "1  [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
       "2  [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
       "3  [{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...   \n",
       "4        [{\"name\": \"Walt Disney Pictures\", \"id\": 2}]   \n",
       "\n",
       "                                production_countries release_date     revenue  \\\n",
       "0  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-12-10  2787965087   \n",
       "1  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2007-05-19   961000000   \n",
       "2  [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2015-10-26   880674609   \n",
       "3  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-07-16  1084939099   \n",
       "4  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-03-07   284139100   \n",
       "\n",
       "   runtime                                   spoken_languages    status  \\\n",
       "0    162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...  Released   \n",
       "1    169.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "2    148.0  [{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...  Released   \n",
       "3    165.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "4    132.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "\n",
       "                                          tagline  \\\n",
       "0                     Enter the World of Pandora.   \n",
       "1  At the end of the world, the adventure begins.   \n",
       "2                           A Plan No One Escapes   \n",
       "3                                 The Legend Ends   \n",
       "4            Lost in our world, found in another.   \n",
       "\n",
       "                                      title  vote_average  vote_count  \n",
       "0                                    Avatar           7.2       11800  \n",
       "1  Pirates of the Caribbean: At World's End           6.9        4500  \n",
       "2                                   Spectre           6.3        4466  \n",
       "3                     The Dark Knight Rises           7.6        9106  \n",
       "4                               John Carter           6.1        2124  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "movies = pd.read_csv('tmdb_5000_movies.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "electoral-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres=movies['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "infinite-liechtenstein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 878, \"name\": \"Science Fiction\"}]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-skirt",
   "metadata": {},
   "source": [
    "We would like to replace this entry with just the names of the genres separated by a comma such as\n",
    "\n",
    " 'Action, Adventure, Fantasy, Science Fiction' \n",
    "\n",
    "How can we go about this? Since each entry is a JSON string, we could use the json module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "driving-testament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Action, Adventure, Fantasy, Science Fiction'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_obj = json.loads(genres[0]) # Load json string\n",
    "names = [x['name'] for x in json_obj] # ['Action', 'Adventure', 'Fantasy', 'Science Fiction']\n",
    "', '.join(names) # 'Action, Adventure, Fantasy, Science Fiction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "maritime-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  transform(s):\n",
    "    s=s.str.strip('[]')\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "framed-weekly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 878, \"name\": \"Science Fiction\"}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres= transform(genres)\n",
    "genres[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sensitive-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(s):\n",
    "    s=s.str.strip('[]')\n",
    "    s=s.str.replace('{','')\n",
    "    s=s.str.replace('}','')\n",
    "    s=s.str.replace(',','')\n",
    "    s=s.str.replace('\\\"id\\\":','')\n",
    "    s=s.str.replace('\\\"name\\\":','')\n",
    "    s=s.str.replace('\"','')\n",
    "    s=s.str.replace('0','')\n",
    "    s=s.str.replace('1','')\n",
    "    s=s.str.replace('2','')\n",
    "    s=s.str.replace('3','')\n",
    "    s=s.str.replace('4','')\n",
    "    s=s.str.replace('5','')\n",
    "    s=s.str.replace('6','')\n",
    "    s=s.str.replace('7','')\n",
    "    s=s.str.replace('8','')\n",
    "    s=s.str.replace('9','')\n",
    "    s=s.str.replace('    ',', ')\n",
    "    s=s.str.replace('   ','')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "italian-ground",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Action, Adventure, Fantasy, Science Fiction'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres= transform(genres)\n",
    "genres[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cordless-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres']=genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "electronic-issue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>Action, Adventure, Fantasy, Science Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Adventure, Fantasy, Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectre</td>\n",
       "      <td>Action, Adventure, Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Action, Crime, Drama, Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Carter</td>\n",
       "      <td>Action, Adventure, Science Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spider-Man 3</td>\n",
       "      <td>Fantasy, Action, Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tangled</td>\n",
       "      <td>Animation, Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>Action, Adventure, Science Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Harry Potter and the Half-Blood Prince</td>\n",
       "      <td>Adventure, Fantasy, Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Batman v Superman: Dawn of Justice</td>\n",
       "      <td>Action, Adventure, Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "3                     The Dark Knight Rises   \n",
       "4                               John Carter   \n",
       "5                              Spider-Man 3   \n",
       "6                                   Tangled   \n",
       "7                   Avengers: Age of Ultron   \n",
       "8    Harry Potter and the Half-Blood Prince   \n",
       "9        Batman v Superman: Dawn of Justice   \n",
       "\n",
       "                                        genres  \n",
       "0  Action, Adventure, Fantasy, Science Fiction  \n",
       "1                   Adventure, Fantasy, Action  \n",
       "2                     Action, Adventure, Crime  \n",
       "3               Action, Crime, Drama, Thriller  \n",
       "4           Action, Adventure, Science Fiction  \n",
       "5                   Fantasy, Action, Adventure  \n",
       "6                            Animation, Family  \n",
       "7           Action, Adventure, Science Fiction  \n",
       "8                   Adventure, Fantasy, Family  \n",
       "9                   Action, Adventure, Fantasy  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.loc[:,['title','genres']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-softball",
   "metadata": {},
   "source": [
    "# Further practice with the movies dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-release",
   "metadata": {},
   "source": [
    "Task: transform the entries of the column keywords so that they each contain the first 3 keywords separated by a comma. For example the entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "finnish-assets",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\": 2964, \"name\": \"future\"}, {\"id\": 3386, \"name\": \"space war\"}, {\"id\": 3388, \"name\": \"space colony\"}, {\"id\": 3679, \"name\": \"society\"}, {\"id\": 3801, \"name\": \"space travel\"}, {\"id\": 9685, \"name\": \"futuristic\"}, {\"id\": 9840, \"name\": \"romance\"}, {\"id\": 9882, \"name\": \"space\"}, {\"id\": 9951, \"name\": \"alien\"}, {\"id\": 10148, \"name\": \"tribe\"}, {\"id\": 10158, \"name\": \"alien planet\"}, {\"id\": 10987, \"name\": \"cgi\"}, {\"id\": 11399, \"name\": \"marine\"}, {\"id\": 13065, \"name\": \"soldier\"}, {\"id\": 14643, \"name\": \"battle\"}, {\"id\": 14720, \"name\": \"love affair\"}, {\"id\": 165431, \"name\": \"anti war\"}, {\"id\": 193554, \"name\": \"power relations\"}, {\"id\": 206690, \"name\": \"mind and soul\"}, {\"id\": 209714, \"name\": \"3d\"}]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.keywords[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-california",
   "metadata": {},
   "source": [
    "**should become 'culture clash, future, space war'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "german-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = movies['keywords']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "conscious-hypothesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    culture clash, future, space war, space colony...\n",
       "1    ocean, drug abuse, exotic island, east india t...\n",
       "2    spy, based on novel, secret agent, sequel, mi,...\n",
       "3    dc comics, crime fighter, terrorist, secret id...\n",
       "4    based on novel, mars, medallion, space travel,...\n",
       "Name: keywords, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = transform(keywords)\n",
    "keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "stable-there",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>culture clash</td>\n",
       "      <td>future</td>\n",
       "      <td>space war</td>\n",
       "      <td>space colony</td>\n",
       "      <td>society</td>\n",
       "      <td>space travel</td>\n",
       "      <td>futuristic</td>\n",
       "      <td>romance</td>\n",
       "      <td>space</td>\n",
       "      <td>alien</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ocean</td>\n",
       "      <td>drug abuse</td>\n",
       "      <td>exotic island</td>\n",
       "      <td>east india trading company</td>\n",
       "      <td>love of one's life</td>\n",
       "      <td>traitor</td>\n",
       "      <td>shipwreck</td>\n",
       "      <td>strong woman</td>\n",
       "      <td>ship</td>\n",
       "      <td>alliance</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spy</td>\n",
       "      <td>based on novel</td>\n",
       "      <td>secret agent</td>\n",
       "      <td>sequel</td>\n",
       "      <td>mi</td>\n",
       "      <td>british secret service</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                1               2   \\\n",
       "0  culture clash           future       space war   \n",
       "1          ocean       drug abuse   exotic island   \n",
       "2            spy   based on novel    secret agent   \n",
       "\n",
       "                            3                    4                        5   \\\n",
       "0                 space colony              society             space travel   \n",
       "1   east india trading company   love of one's life                  traitor   \n",
       "2                       sequel                   mi   british secret service   \n",
       "\n",
       "                6              7       8          9   ...    87    88    89  \\\n",
       "0       futuristic        romance   space      alien  ...  None  None  None   \n",
       "1        shipwreck   strong woman    ship   alliance  ...  None  None  None   \n",
       "2   united kingdom           None    None       None  ...  None  None  None   \n",
       "\n",
       "     90    91    92    93    94    95    96  \n",
       "0  None  None  None  None  None  None  None  \n",
       "1  None  None  None  None  None  None  None  \n",
       "2  None  None  None  None  None  None  None  \n",
       "\n",
       "[3 rows x 97 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_df = keywords.str.split(',' , expand = True)\n",
    "keywords_df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "pretty-lesson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>Action, Adventure, Fantasy, Science Fiction</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>culture clash,  future,  space war</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>Adventure, Fantasy, Action</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285</td>\n",
       "      <td>ocean,  drug abuse,  exotic island</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>Action, Adventure, Crime</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>spy,  based on novel,  secret agent</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250000000</td>\n",
       "      <td>Action, Crime, Drama, Thriller</td>\n",
       "      <td>http://www.thedarkknightrises.com/</td>\n",
       "      <td>49026</td>\n",
       "      <td>dc comics,  crime fighter,  terrorist</td>\n",
       "      <td>en</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "      <td>112.312950</td>\n",
       "      <td>[{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>1084939099</td>\n",
       "      <td>165.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Legend Ends</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260000000</td>\n",
       "      <td>Action, Adventure, Science Fiction</td>\n",
       "      <td>http://movies.disney.com/john-carter</td>\n",
       "      <td>49529</td>\n",
       "      <td>based on novel,  mars,  medallion</td>\n",
       "      <td>en</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "      <td>43.926995</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-03-07</td>\n",
       "      <td>284139100</td>\n",
       "      <td>132.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Lost in our world, found in another.</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget                                       genres  \\\n",
       "0  237000000  Action, Adventure, Fantasy, Science Fiction   \n",
       "1  300000000                   Adventure, Fantasy, Action   \n",
       "2  245000000                     Action, Adventure, Crime   \n",
       "3  250000000               Action, Crime, Drama, Thriller   \n",
       "4  260000000           Action, Adventure, Science Fiction   \n",
       "\n",
       "                                       homepage      id  \\\n",
       "0                   http://www.avatarmovie.com/   19995   \n",
       "1  http://disney.go.com/disneypictures/pirates/     285   \n",
       "2   http://www.sonypictures.com/movies/spectre/  206647   \n",
       "3            http://www.thedarkknightrises.com/   49026   \n",
       "4          http://movies.disney.com/john-carter   49529   \n",
       "\n",
       "                                keywords original_language  \\\n",
       "0     culture clash,  future,  space war                en   \n",
       "1     ocean,  drug abuse,  exotic island                en   \n",
       "2    spy,  based on novel,  secret agent                en   \n",
       "3  dc comics,  crime fighter,  terrorist                en   \n",
       "4      based on novel,  mars,  medallion                en   \n",
       "\n",
       "                             original_title  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "3                     The Dark Knight Rises   \n",
       "4                               John Carter   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "1  Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
       "2  A cryptic message from Bond’s past sends him o...  107.376788   \n",
       "3  Following the death of District Attorney Harve...  112.312950   \n",
       "4  John Carter is a war-weary, former military ca...   43.926995   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
       "1  [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
       "2  [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
       "3  [{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...   \n",
       "4        [{\"name\": \"Walt Disney Pictures\", \"id\": 2}]   \n",
       "\n",
       "                                production_countries release_date     revenue  \\\n",
       "0  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-12-10  2787965087   \n",
       "1  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2007-05-19   961000000   \n",
       "2  [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2015-10-26   880674609   \n",
       "3  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-07-16  1084939099   \n",
       "4  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-03-07   284139100   \n",
       "\n",
       "   runtime                                   spoken_languages    status  \\\n",
       "0    162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...  Released   \n",
       "1    169.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "2    148.0  [{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...  Released   \n",
       "3    165.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "4    132.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "\n",
       "                                          tagline  \\\n",
       "0                     Enter the World of Pandora.   \n",
       "1  At the end of the world, the adventure begins.   \n",
       "2                           A Plan No One Escapes   \n",
       "3                                 The Legend Ends   \n",
       "4            Lost in our world, found in another.   \n",
       "\n",
       "                                      title  vote_average  vote_count  \n",
       "0                                    Avatar           7.2       11800  \n",
       "1  Pirates of the Caribbean: At World's End           6.9        4500  \n",
       "2                                   Spectre           6.3        4466  \n",
       "3                     The Dark Knight Rises           7.6        9106  \n",
       "4                               John Carter           6.1        2124  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['keywords'] = keywords_df[0] + ', ' + keywords_df[1] + ', ' + keywords_df[2]\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-liechtenstein",
   "metadata": {},
   "source": [
    "# Regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sporting-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=pd.Series(['0', 'John Wood', 'Colin Welsh', 'my list', '02456', np.nan, 'HELLO WORLD', 'water%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "likely-cable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5      NaN\n",
       "6    False\n",
       "7    False\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.contains('John')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "harmful-junction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2     True\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.contains('John') | s.str.contains('Colin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "guided-batch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2     True\n",
       "3    False\n",
       "4    False\n",
       "5      NaN\n",
       "6    False\n",
       "7    False\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.str.contains('John|Colin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "covered-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = pd.Series(['bar', 'sugar', 'cartoon', 'argon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "theoretical-declaration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2     True\n",
       "3    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.str.contains('.ar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "soviet-auckland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.str.contains('[bc]ar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-beginning",
   "metadata": {},
   "source": [
    "We can also specify inside the square brackets what kind of characters we want to match as follows:\n",
    "\n",
    "- [a-z] - match any lowercase letter\n",
    "- [A-Z] - match any uppercase letter\n",
    "- [0-9] - match any digit\n",
    "- [a-zA-Z0-9] - match any letter or digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "employed-request",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "4    02456\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[s.str.contains('[0-9]', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-muscle",
   "metadata": {},
   "source": [
    "- [^a-z] - match any character that is not a lowercase letter\n",
    "- [^A-Z] - match any character that is not a uppercase letter\n",
    "- [^0-9] - match any character that is not a digit\n",
    "- [^a-zA-Z0-9] - match any character that is not a letter or digit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-affiliation",
   "metadata": {},
   "source": [
    "- \\d - match any digit\n",
    "- \\D - match any non digit\n",
    "- \\w - match a word character\n",
    "- \\W - match a non-word character\n",
    "- \\s - match whitespace (spaces, tabs, newlines, etc.)\n",
    "- \\S - match non-whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "center-module",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "4    02456\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[s.str.contains('[\\d]', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-phrase",
   "metadata": {},
   "source": [
    "#### Matching at the start and end of strings\n",
    "We can also specify the location of the string where we want to match by using\n",
    "\n",
    "- ^ - match at the beginning of a string\n",
    "- $ - searches for matches at the end of a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "latest-services",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        bar\n",
       "2    cartoon\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2[s2.str.contains('^[bc]', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "verified-jenny",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      bar\n",
       "1    sugar\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2[s2.str.contains('ar$', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-floating",
   "metadata": {},
   "source": [
    "#### Matching preceding characters\n",
    "Often we want to mention a certain character and then ask to match one or more copies of this character. We can do this using the following metacharacters"
   ]
  },
  {
   "cell_type": "raw",
   "id": "touched-picture",
   "metadata": {},
   "source": [
    "- * - match zero or more copies of the preceding character\n",
    "- ? - match zero or 1 copy of the preceding character\n",
    "- + - match 1 or more copies of the preceding character\n",
    "Or we can use curly braces to specify how many time we want to match the given character. We have the following choices\n",
    "\n",
    "- {m} - match the preceding element m times\n",
    "- {m,} - match the preceding element m times or more\n",
    "- {m,n} - match the preceding element between m and n times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "living-checklist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "4     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3= pd.Series(['forest', 'o', 'ff', 'foo', 'fof'])\n",
    "s3.str.contains('f+o?f+')\n",
    "# What this does is search for all strings that contain 1 or more f's then an optional o and then 1 or more f's. We can see that the third and fifth strings satisfy this as shown in the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-bangkok",
   "metadata": {},
   "source": [
    "An important thing to know is that the backslash character \\ lets us escape regular expressions, for situations where we want to match the metacharacter itself. For example, if we want to match periods we cannot just use . since this will match any character as we mentioned before. We must use instead \\.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-mercury",
   "metadata": {},
   "source": [
    "#### Grouping\n",
    "We can place parentheses around a regular expression to allow us to group the results so that we can extract each component separately instead of the full match. This can be especially useful if we want to use the str.extract() method since in this case we must have the matches grouped so that they can be extracted in a new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "hispanic-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "s4= pd.Series(['Monday5km', 'Wednesday10km', 'Saturday25km'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ahead-allocation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0     Monday\n",
       "1  Wednesday\n",
       "2   Saturday"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4.str.extract('(\\w+day)',expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-baking",
   "metadata": {},
   "source": [
    "Let's break the regular expression \n",
    "\\w+day\n",
    " down:\n",
    "\n",
    "- \\w\n",
    ": matches a word character once (it is equivalent to \n",
    "[a-zA-Z0-9_]\n",
    ").\n",
    "- If you add the \n",
    "+\n",
    " quantifier, this will match the preceding character 1 or more times. So, \n",
    "\\w+\n",
    " will match word characters 1 or more times.\n",
    "- day\n",
    ": matches the characters \"day\" literally (case sensitive).\n",
    "Altogether, \n",
    "\\w+day\n",
    " will match any word characters preceding the string \"day\", and then the string \"day\". It won't match anything after the string \"day\".\n",
    "\n",
    "I hope it is now clear why \n",
    "(\\w)\n",
    " will match only one word character.\n",
    "\n",
    "The regular expression pattern: \n",
    "\\w+y\n",
    ", will match any word characters preceding the string \"y\", and then the string \"y\". In practice, this will match the whole day name, without matching any characters after the string \"y\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-paintball",
   "metadata": {},
   "source": [
    "Note that the command would not have worked had we not used the parentheses to indicate that we want to group the matches. That is every time we use the str.extract() function we must use this option to group the results.\n",
    "\n",
    "Grouping the results also means that we can refer to them. Let's look at a particular example where we want to take each match of the previous regular expression '\\w+day' and now replace each string the first three letters so that we have the abbreviated names 'Mon', 'Wed' and 'Sat'. For this we can use the str.replace() function. Normally we would need to provide a fixed string by which to replace every match. However, if we choose to group our matches using parentheses then we have the option to specify a function which gives a separate replacement string to each match in the group. In our case this function has to take the first three characters of each string. We define the function as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "enabling-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x.groups()[0][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-copying",
   "metadata": {},
   "source": [
    "**The groups attribute refers to the fact that the matches are grouped, and now we index the first and only group in this case and ask for the first three characters to be returned for each match.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "foreign-interstate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Mon5km\n",
       "1    Wed10km\n",
       "2    Sat25km\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4.str.replace('(\\w+day)', f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-ecology",
   "metadata": {},
   "source": [
    "# Exercise: using regular expressions in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "previous-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_plan = ['Monday: 9:12am – Omelet,  3:30pm– Apple slices with almond butter', \n",
    "             'Tuesday: 9:35am – Banana bread, 11:00am –Sauteed veggies, 7:02pm– Taco pie',\n",
    "             'Wednesday: 9:00am – Banana pancakes',  \n",
    "             'Thursday: 7:23pm– Slow cooker pulled pork', 'Friday: 3:30pm – Can of tuna', \n",
    "             'Saturday: 9:11am: Eggs and sweet potato hash browns, 3:22pm: Almonds', \n",
    "             'Sunday: 11:00am: Meat and veggie stir fry'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "lesser-first",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday: 9:12am – Omelet,  3:30pm– Apple slices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday: 9:35am – Banana bread, 11:00am –Saute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday: 9:00am – Banana pancakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday: 7:23pm– Slow cooker pulled pork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday: 3:30pm – Can of tuna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturday: 9:11am: Eggs and sweet potato hash b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sunday: 11:00am: Meat and veggie stir fry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Monday: 9:12am – Omelet,  3:30pm– Apple slices...\n",
       "1  Tuesday: 9:35am – Banana bread, 11:00am –Saute...\n",
       "2                Wednesday: 9:00am – Banana pancakes\n",
       "3          Thursday: 7:23pm– Slow cooker pulled pork\n",
       "4                       Friday: 3:30pm – Can of tuna\n",
       "5  Saturday: 9:11am: Eggs and sweet potato hash b...\n",
       "6          Sunday: 11:00am: Meat and veggie stir fry"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(meal_plan, columns=['text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "overall-oracle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>02</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>00</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0   1   2\n",
       "  match            \n",
       "0 0       9  12  am\n",
       "  1       3  30  pm\n",
       "1 0       9  35  am\n",
       "  1      11  00  am\n",
       "  2       7  02  pm\n",
       "2 0       9  00  am\n",
       "3 0       7  23  pm\n",
       "4 0       3  30  pm\n",
       "5 0       9  11  am\n",
       "  1       3  22  pm\n",
       "6 0      11  00  am"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol = df['text'].str.extractall(('(\\d?\\d):(\\d\\d) ?([ap]m)'))\n",
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "expensive-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "days=['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\n",
    "meals = ['breakfast','lunch','dinner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "structured-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.index.set_levels([days,meals],inplace = True)\n",
    "sol.index.set_names(['Day','Meal'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "better-inspector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <th>Meal</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Mon</th>\n",
       "      <th>breakfast</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Tue</th>\n",
       "      <th>breakfast</th>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dinner</th>\n",
       "      <td>7</td>\n",
       "      <td>02</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wed</th>\n",
       "      <th>breakfast</th>\n",
       "      <td>9</td>\n",
       "      <td>00</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thu</th>\n",
       "      <th>breakfast</th>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fri</th>\n",
       "      <th>breakfast</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sat</th>\n",
       "      <th>breakfast</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sun</th>\n",
       "      <th>breakfast</th>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0   1   2\n",
       "Day Meal                 \n",
       "Mon breakfast   9  12  am\n",
       "    lunch       3  30  pm\n",
       "Tue breakfast   9  35  am\n",
       "    lunch      11  00  am\n",
       "    dinner      7  02  pm\n",
       "Wed breakfast   9  00  am\n",
       "Thu breakfast   7  23  pm\n",
       "Fri breakfast   3  30  pm\n",
       "Sat breakfast   9  11  am\n",
       "    lunch       3  22  pm\n",
       "Sun breakfast  11  00  am"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ranking-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.columns=['Hour','Minutes','Period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "appointed-viking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minutes</th>\n",
       "      <th>Period</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <th>Meal</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Mon</th>\n",
       "      <th>breakfast</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Tue</th>\n",
       "      <th>breakfast</th>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dinner</th>\n",
       "      <td>7</td>\n",
       "      <td>02</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wed</th>\n",
       "      <th>breakfast</th>\n",
       "      <td>9</td>\n",
       "      <td>00</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thu</th>\n",
       "      <th>breakfast</th>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fri</th>\n",
       "      <th>breakfast</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sat</th>\n",
       "      <th>breakfast</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sun</th>\n",
       "      <th>breakfast</th>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Hour Minutes Period\n",
       "Day Meal                         \n",
       "Mon breakfast    9      12     am\n",
       "    lunch        3      30     pm\n",
       "Tue breakfast    9      35     am\n",
       "    lunch       11      00     am\n",
       "    dinner       7      02     pm\n",
       "Wed breakfast    9      00     am\n",
       "Thu breakfast    7      23     pm\n",
       "Fri breakfast    3      30     pm\n",
       "Sat breakfast    9      11     am\n",
       "    lunch        3      22     pm\n",
       "Sun breakfast   11      00     am"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-store",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-proposition",
   "metadata": {},
   "source": [
    "In this unit we showcase the work flow of a real-life example of data science: Sentiment analysis for tweets. In the process we will come across our **first example of machine learning.** Using a package called nltk, we will walk you through the text-processing steps necessary for transforming the text data from our tweets into a numerical representation for our machine learning model (a Naive Bayes Classifier). Try to understand the main ideas but don't worry about the precise implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dramatic-journalist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          4  @stellargirl I loooooooovvvvvveee my Kindle2. ...\n",
       "1          4  Reading my kindle2...  Love it... Lee childs i...\n",
       "2          4  Ok, first assesment of the #kindle2 ...it fuck...\n",
       "3          4  @kenburbary You'll love your Kindle2. I've had...\n",
       "4          4  @mikefish  Fair enough. But i have the Kindle2..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('tweets.csv', header=None)\n",
    "df.columns = ['sentiment','text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "lightweight-shirt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total number of tweets\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "reflected-amendment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of positive tweets\n",
    "df[df['sentiment']==4].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "gentle-enemy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of neutral tweets\n",
    "df[df['sentiment']==2].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "criminal-squad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of negative tweets\n",
    "df[df['sentiment']==0].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "official-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = df.loc[df['sentiment']==4,'text']\n",
    "neg_tweets = df.loc[df['sentiment']==0,'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-regular",
   "metadata": {},
   "source": [
    "We will now clean up our tweets. Our goal here is to reduce each tweet to a list of essential words. These words should not contain any symbols and they should not be stopwords. **This process of turning text into a list of essential words is known as tokenization**. Luckily, in Python, we have the choice of many useful text processing libraries that can help us with such tasks as cleanup and tokenization. In this exercise, we will use perhaps **the NLTK library**. We will also download its list of English stopwords so that we do not have to define our own. There is even a special TweetTokenizer object that will automatically remove symbols and hashtags from our tweets and turn them into a list of essential words. We need to add the following import commands to the top of our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "experimental-compiler",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Utilisateur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "global-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english = stopwords.words('english')\n",
    "# Happy Emoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "funky-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "weighted-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons = emoticons_happy.union(emoticons_sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "level-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/[^\\s]+', '', tweet)\n",
    "\n",
    "    # remove hashtags\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []    \n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and # remove stopwords\n",
    "            word not in emoticons and # remove emoticons\n",
    "            word not in string.punctuation): # remove punctuation\n",
    "            tweets_clean.append(word)   \n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cardiac-consultation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@mikefish  Fair enough. But i have the Kindle2 and I think it's perfect  :)\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pos_tweets.iloc[4]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cognitive-accessory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fair', 'enough', 'kindle', '2', 'think', 'perfect']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-appeal",
   "metadata": {},
   "source": [
    "We have turned our original tweet into a list of meaningful words. The next step will be to turn this list of meaningful words into a feature vector, by **counting the frequency of each word**. This is known in natural language processing literature as the bag of words model, whereas a string of text is represented by just a word vector and their corresponding frequencies. Let's now define our feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "alien-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tweet):\n",
    "    words = clean_tweets(tweet)\n",
    "    words_dictionary = dict([word, True] for word in words)    \n",
    "    return words_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-wiring",
   "metadata": {},
   "source": [
    "This routine simply calls the previous cleaning routine on each tweet and creates a dictionary with a True value for each of the appearing words. Here is a demonstration on our previous sample tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "innocent-magic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fair': True,\n",
       " 'enough': True,\n",
       " 'kindle': True,\n",
       " '2': True,\n",
       " 'think': True,\n",
       " 'perfect': True}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "particular-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive tweets feature set\n",
    "pos_tweets_set = []\n",
    "for tweet in pos_tweets:\n",
    "    pos_tweets_set.append((bag_of_words(tweet), 'pos'))    \n",
    "\n",
    "#negative tweets feature set\n",
    "neg_tweets_set = []\n",
    "for tweet in neg_tweets:\n",
    "    neg_tweets_set.append((bag_of_words(tweet), 'neg'))\n",
    "\n",
    "tweets = pos_tweets_set + neg_tweets_set  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-credit",
   "metadata": {},
   "source": [
    "#### The Naive Bayes classifier\n",
    "The Naive-Bayes classifier is a probabilistic classifier that is based on Baye’s theorem. Given a feature vector \n",
    "x\n",
    "=\n",
    "(\n",
    "x\n",
    "1\n",
    ",\n",
    "⋯\n",
    ",\n",
    "x\n",
    "n\n",
    ")\n",
    " the algorithm predicts the conditional probability \n",
    "P\n",
    "(\n",
    "C\n",
    "k\n",
    "|\n",
    "x\n",
    ")\n",
    " for each possible class Ck. The probability is computed using Baye’s Theorem as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-chambers",
   "metadata": {},
   "source": [
    "P\n",
    "(\n",
    "C\n",
    "k\n",
    "|\n",
    "x\n",
    ")\n",
    "=\n",
    "P\n",
    "(\n",
    "C\n",
    "k\n",
    ")\n",
    "P\n",
    "(\n",
    "x\n",
    "|\n",
    "C\n",
    "k\n",
    ")\n",
    "/\n",
    "P\n",
    "(\n",
    "x\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-accent",
   "metadata": {},
   "source": [
    "It then assigns the tweet to the class achieving the highest conditional probability. Since the denominator is constant for each possible class, the problem is reduced to computing the numerator, which is equal to the joint probability\n",
    "\n",
    "P\n",
    "(\n",
    "C\n",
    "k\n",
    ")\n",
    "P\n",
    "(\n",
    "x\n",
    "|\n",
    "C\n",
    "k\n",
    ")\n",
    "=\n",
    "P\n",
    "(\n",
    "C\n",
    "k\n",
    ",\n",
    "x\n",
    "1\n",
    ",\n",
    "⋯\n",
    ",\n",
    "x\n",
    "n\n",
    ")\n",
    "\n",
    "Using the law of total probability this can be rewritten as\n",
    "\n",
    "\n",
    "P(\n",
    "C\n",
    "k\n",
    ",\n",
    "x\n",
    "1\n",
    ",\n",
    "⋯\n",
    ",\n",
    "x\n",
    "n\n",
    ")\n",
    "=\n",
    "P\n",
    "(\n",
    "x\n",
    "1\n",
    "|\n",
    "x\n",
    "2\n",
    ",\n",
    "⋯\n",
    ",\n",
    "x\n",
    "n\n",
    ",\n",
    "C\n",
    "k\n",
    ")\n",
    "⋯\n",
    "P\n",
    "(\n",
    "x\n",
    "n\n",
    "−\n",
    "1\n",
    "|\n",
    "x\n",
    "n\n",
    ",\n",
    "C\n",
    "k\n",
    ")\n",
    "P\n",
    "(\n",
    "x\n",
    "n\n",
    "|\n",
    "C\n",
    "k\n",
    ")\n",
    "P\n",
    "(\n",
    "C\n",
    "k\n",
    ")\n",
    "\n",
    "The algorithm now makes the simplifying assumption that each feature xi is independent of any other feature \n",
    "x\n",
    "j\n",
    " conditional on the class \n",
    "C\n",
    "k\n",
    " . This is where the name “Naive” comes from. This means that the probability above can be simply computed as\n",
    " \n",
    " P\n",
    "(\n",
    "C\n",
    "k\n",
    ",\n",
    "x\n",
    "1\n",
    ",\n",
    "⋯\n",
    ",\n",
    "x\n",
    "n\n",
    ")\n",
    "=\n",
    "P\n",
    "(\n",
    "C\n",
    "k\n",
    ")\n",
    "n\n",
    "∏\n",
    "i\n",
    "=\n",
    "1\n",
    " P\n",
    "(\n",
    "x\n",
    "i\n",
    "|\n",
    "C\n",
    "k\n",
    ")\n",
    "\n",
    "These probabilities are now computed using the training data which consists of a set of prelabelled tweets. The priori probability \n",
    "P\n",
    "(\n",
    "C\n",
    "k\n",
    ")\n",
    " of each class is computed by checking the frequency of each class in the training data. The probability \n",
    "P\n",
    "(\n",
    "x\n",
    "i\n",
    "|\n",
    "C\n",
    "k\n",
    ")\n",
    " is computed by checking the frequency that the word xi occurs in tweets labeled as class \n",
    "C\n",
    "k\n",
    " in the training data. Finally, the class with the highest probability is assigned to each unlabelled tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-reverse",
   "metadata": {},
   "source": [
    "#### Implementation\n",
    "We will now use our feature sets to implement the Naive Bayes algorithm from the NLTK library. First, we randomly split our data in about 20% test set and 80% training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "sublime-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle \n",
    "shuffle(pos_tweets_set)\n",
    "shuffle(neg_tweets_set)\n",
    "\n",
    "test_set = pos_tweets_set[:36] + neg_tweets_set[:36]\n",
    "train_set = pos_tweets_set[36:] + neg_tweets_set[36:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-wallace",
   "metadata": {},
   "source": [
    "We now feed the training set directly to the Naive Bayes classifier. In order to use this classifier we need to add the following import statements at the top of our notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "going-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier\n",
    "classifier = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "improved-webster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = classify.accuracy(classifier, test_set)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "understanding-roberts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                       2 = True              pos : neg    =     11.9 : 1.0\n",
      "                    hate = True              neg : pos    =      9.3 : 1.0\n",
      "                    time = True              neg : pos    =      9.0 : 1.0\n",
      "                  kindle = True              pos : neg    =      8.0 : 1.0\n",
      "                    love = True              pos : neg    =      6.8 : 1.0\n",
      "                    best = True              pos : neg    =      5.5 : 1.0\n",
      "                   still = True              neg : pos    =      5.2 : 1.0\n",
      "                    want = True              pos : neg    =      4.8 : 1.0\n",
      "                   phone = True              neg : pos    =      3.8 : 1.0\n",
      "                    fail = True              neg : pos    =      3.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-allergy",
   "metadata": {},
   "source": [
    "How should we interpret this chart? It simply means that if the word great appears in the tweet then the sentiment is 5.9 times more likely to be positive than negative. On the other hand, if the word safeway appears in the tweet then the sentiment is 4.8 times more likely to be negative than positive.\n",
    "\n",
    "Another useful property to look at is what is called the confusion matrix. This tells us exactly how many positive and negative tweets we are labeling correctly and incorrectly. Here is how to obtain it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "institutional-revelation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |  n  p |\n",
      "    |  e  o |\n",
      "    |  g  s |\n",
      "----+-------+\n",
      "neg |<30> 6 |\n",
      "pos |  6<30>|\n",
      "----+-------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "\n",
    "actual_set = defaultdict(set)\n",
    "predicted_set = defaultdict(set)\n",
    "\n",
    "actual_set_cm = []\n",
    "predicted_set_cm = []\n",
    "\n",
    "for index, (feature, actual_label) in enumerate(test_set):\n",
    "    actual_set[actual_label].add(index)\n",
    "    actual_set_cm.append(actual_label)\n",
    "\n",
    "    predicted_label = classifier.classify(feature)\n",
    "\n",
    "    predicted_set[predicted_label].add(index)\n",
    "    predicted_set_cm.append(predicted_label)\n",
    "\n",
    "print(ConfusionMatrix(actual_set_cm, predicted_set_cm)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-victor",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-religion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
