{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02737602",
   "metadata": {},
   "source": [
    "# Convolutional Networks\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb04df2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lyeso\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING:absl:Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn as skl\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"-1\" # Force Tensorflow on CPU instead of GPU (seems to avoid an error with my CUDA compatible GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3833f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data form NPZ file\n",
    "\n",
    "train_data = \"train.npz\"\n",
    "X_tr = np.load(train_data)[\"features\"]\n",
    "y_tr = np.load(train_data)[\"labels\"]\n",
    "images_tr = np.load(train_data)[\"pixels\"]\n",
    "names_tr = np.load(train_data)[\"names\"]\n",
    "\n",
    "valid_data = \"valid.npz\"\n",
    "X_val= np.load(valid_data)[\"features\"]\n",
    "y_val = np.load(valid_data)[\"labels\"]\n",
    "images_val = np.load(valid_data)[\"pixels\"]\n",
    "names_val = np.load(valid_data)[\"names\"]\n",
    "\n",
    "test_data = \"test.npz\"\n",
    "X_te= np.load(test_data)[\"features\"]\n",
    "y_te = np.load(test_data)[\"labels\"]\n",
    "images_te = np.load(test_data)[\"pixels\"]\n",
    "names_te = np.load(test_data)[\"names\"]\n",
    "\n",
    "# Create a dictionnary for labels\n",
    "labels_dict = {0: 'bike', 1 : 'car', 2: 'motorcycle', 3: 'other', 4:'truck', 5: 'van'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd833aeb",
   "metadata": {},
   "source": [
    "### Let's use the train generator to have more images to train on and use in the Convolutional Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1451d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image generator\n",
    "train_generator = ImageDataGenerator(rescale=1/255, rotation_range = 10, horizontal_flip = True, vertical_flip = False)\n",
    "test_generator = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38aaba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 6 classes.\n",
      "Found 139 images belonging to 6 classes.\n",
      "Found 50 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Train, validation and test sets\n",
    "\n",
    "\n",
    "# class_mode = categorical to have a one hot encoded \"y\" output.\n",
    "\n",
    "trainset = train_generator.flow_from_directory(\n",
    "    os.path.join('Course Project - SwissRoads', 'train'), batch_size =500, target_size=(299, 299),\n",
    "    shuffle=True, color_mode='rgb', class_mode = 'categorical') \n",
    "\n",
    "validset = test_generator.flow_from_directory(\n",
    "    os.path.join('Course Project - SwissRoads', 'valid'),batch_size =500, target_size=(299, 299),\n",
    "    shuffle=False, color_mode='rgb', class_mode = 'categorical')\n",
    "testset = test_generator.flow_from_directory(\n",
    "    os.path.join('Course Project - SwissRoads', 'test'),batch_size =500, target_size=(299, 299),\n",
    "    shuffle=False,color_mode='rgb', class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572f65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5a859a6",
   "metadata": {},
   "source": [
    "### Let's create a 2 layers convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0504a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d558a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82998c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 148, 148, 128)     9728      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 74, 74, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 72, 72, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 497670    \n",
      "=================================================================\n",
      "Total params: 581,190\n",
      "Trainable params: 581,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Network\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=128, kernel_size=5, strides=2,\n",
    "                              activation='relu', input_shape=(299, 299, 3)))\n",
    "\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=3, strides=1,\n",
    "                              activation='relu'))\n",
    "\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(Dropout(rate=0.5)) # because of overfitting\n",
    "\n",
    "model.add(keras.layers.Dense(units=trainset.num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f22954c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b68f27b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End training when accuracy stops improving (optional)\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2aad4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "123b1729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 24s 24s/step - loss: 1.7873 - acc: 0.2143 - val_loss: 2.6355 - val_acc: 0.2374\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 2.5734 - acc: 0.2464 - val_loss: 1.9419 - val_acc: 0.1799\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.8941 - acc: 0.1821 - val_loss: 1.7939 - val_acc: 0.2158\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.7820 - acc: 0.2429 - val_loss: 1.7858 - val_acc: 0.1511\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.7821 - acc: 0.1607 - val_loss: 1.7586 - val_acc: 0.3525\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.7526 - acc: 0.3643 - val_loss: 1.7416 - val_acc: 0.2230\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.7285 - acc: 0.2607 - val_loss: 1.7276 - val_acc: 0.2950\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.7103 - acc: 0.3321 - val_loss: 1.7035 - val_acc: 0.3741\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.6867 - acc: 0.3964 - val_loss: 1.6819 - val_acc: 0.3237\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.6578 - acc: 0.3786 - val_loss: 1.6645 - val_acc: 0.3309\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.6359 - acc: 0.3714 - val_loss: 1.6470 - val_acc: 0.3669\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.6048 - acc: 0.4821 - val_loss: 1.6098 - val_acc: 0.3741\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.5621 - acc: 0.4714 - val_loss: 1.5806 - val_acc: 0.4173\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.5138 - acc: 0.4821 - val_loss: 1.5355 - val_acc: 0.4532\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.4535 - acc: 0.5107 - val_loss: 1.5031 - val_acc: 0.4748\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.3937 - acc: 0.5536 - val_loss: 1.4437 - val_acc: 0.4676\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.3417 - acc: 0.5464 - val_loss: 1.4811 - val_acc: 0.4173\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.3032 - acc: 0.5643 - val_loss: 1.4068 - val_acc: 0.4532\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.2657 - acc: 0.5500 - val_loss: 1.3561 - val_acc: 0.4964\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.1665 - acc: 0.5786 - val_loss: 1.4156 - val_acc: 0.4101\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.1525 - acc: 0.5643 - val_loss: 1.3340 - val_acc: 0.5108\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.1139 - acc: 0.6464 - val_loss: 1.2825 - val_acc: 0.5252\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.0521 - acc: 0.6536 - val_loss: 1.3327 - val_acc: 0.4820\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.0363 - acc: 0.5821 - val_loss: 1.3335 - val_acc: 0.4676\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.9829 - acc: 0.6536 - val_loss: 1.2715 - val_acc: 0.5396\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.9051 - acc: 0.6857 - val_loss: 1.2820 - val_acc: 0.5108\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.9130 - acc: 0.6536 - val_loss: 1.2482 - val_acc: 0.5108\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.8389 - acc: 0.7321 - val_loss: 1.3322 - val_acc: 0.4892\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.8405 - acc: 0.7107 - val_loss: 1.2643 - val_acc: 0.5036\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.7422 - acc: 0.7429 - val_loss: 1.3050 - val_acc: 0.5180\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.7725 - acc: 0.7357 - val_loss: 1.3068 - val_acc: 0.5180\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.6787 - acc: 0.7750 - val_loss: 1.3442 - val_acc: 0.4676\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.6496 - acc: 0.7929 - val_loss: 1.3575 - val_acc: 0.4748\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit_generator(\n",
    "    generator = trainset, \n",
    "    validation_data = validset, \n",
    "    epochs=100, \n",
    "    callbacks=[early_stopping],\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2dad7d",
   "metadata": {},
   "source": [
    "### Let's change y_tr, with One Hot Encoding to implement in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c057c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder as ohe\n",
    "\n",
    "nominal_transformer = ohe(handle_unknown='ignore', sparse = False)\n",
    "\n",
    "y_tr_ohe = nominal_transformer.fit_transform(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_transposed = y_tr.transpose()\n",
    "y_tr_transposed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428a91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f8edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit(\n",
    "    x = images_tr, \n",
    "    y = y_tr, \n",
    "    epochs=100,\n",
    "    validation_split = 0.2,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168ba521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
