{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c8ce39",
   "metadata": {},
   "source": [
    "# Convolutional Networks\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc40cbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lyeso\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING:absl:Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn as skl\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"-1\" # Force Tensorflow on CPU instead of GPU (seems to avoid an error with my CUDA compatible GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a65ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data form NPZ file\n",
    "\n",
    "train_data = \"train.npz\"\n",
    "X_tr = np.load(train_data)[\"features\"]\n",
    "y_tr = np.load(train_data)[\"labels\"]\n",
    "images_tr = np.load(train_data)[\"pixels\"]\n",
    "names_tr = np.load(train_data)[\"names\"]\n",
    "\n",
    "valid_data = \"valid.npz\"\n",
    "X_val= np.load(valid_data)[\"features\"]\n",
    "y_val = np.load(valid_data)[\"labels\"]\n",
    "images_val = np.load(valid_data)[\"pixels\"]\n",
    "names_val = np.load(valid_data)[\"names\"]\n",
    "\n",
    "test_data = \"test.npz\"\n",
    "X_te= np.load(test_data)[\"features\"]\n",
    "y_te = np.load(test_data)[\"labels\"]\n",
    "images_te = np.load(test_data)[\"pixels\"]\n",
    "names_te = np.load(test_data)[\"names\"]\n",
    "\n",
    "# Create a dictionnary for labels\n",
    "labels_dict = {0: 'bike', 1 : 'car', 2: 'motorcycle', 3: 'other', 4:'truck', 5: 'van'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ebf2908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 299, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_tr[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a5cce0",
   "metadata": {},
   "source": [
    "### Let's use the train generator to have more images to train on and use in the Convolutional Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "084250a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image generator\n",
    "train_generator = ImageDataGenerator(rescale=1/255, rotation_range = 10, horizontal_flip = True, vertical_flip = False, zoom_range = 0.2)\n",
    "test_generator = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b19f2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 6 classes.\n",
      "Found 139 images belonging to 6 classes.\n",
      "Found 50 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Train, validation and test sets\n",
    "\n",
    "\n",
    "# class_mode = categorical to have a one hot encoded \"y\" output.\n",
    "\n",
    "trainset = train_generator.flow_from_directory(\n",
    "    os.path.join('Course Project - SwissRoads', 'train'), batch_size =500,\n",
    "    shuffle=True, color_mode='rgb', class_mode = 'categorical') \n",
    "\n",
    "validset = test_generator.flow_from_directory(\n",
    "    os.path.join('Course Project - SwissRoads', 'valid'),batch_size =500,\n",
    "    shuffle=False, color_mode='rgb', class_mode = 'categorical')\n",
    "testset = test_generator.flow_from_directory(\n",
    "    os.path.join('Course Project - SwissRoads', 'test'),batch_size =500,\n",
    "    shuffle=False,color_mode='rgb', class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c46ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7bf9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62830850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e57bb692",
   "metadata": {},
   "source": [
    "### Let's create a 2 layers convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025c0b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "890d9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7261d194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 84, 84, 128)       9728      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 42, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 9, 16)          4112      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 89,174\n",
      "Trainable params: 89,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Network\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=128, kernel_size=5, strides=3, activation='relu', input_shape=(256, 256, 3)))\n",
    "\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=16, kernel_size=2, strides=1, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(Dropout(rate=0.3)) # because of overfitting\n",
    "\n",
    "model.add(keras.layers.Dense(units=trainset.num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0396157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdd9bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End training when accuracy stops improving (optional)\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "851280bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dea8d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 10s 10s/step - loss: 1.8400 - acc: 0.1107 - val_loss: 1.7878 - val_acc: 0.1511\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.7871 - acc: 0.1679 - val_loss: 1.7835 - val_acc: 0.1799\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7884 - acc: 0.1929 - val_loss: 1.7830 - val_acc: 0.1727\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7824 - acc: 0.1964 - val_loss: 1.7772 - val_acc: 0.1799\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 8s 8s/step - loss: 1.7804 - acc: 0.1821 - val_loss: 1.7730 - val_acc: 0.1871\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7818 - acc: 0.1786 - val_loss: 1.7695 - val_acc: 0.2446\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7616 - acc: 0.2321 - val_loss: 1.7642 - val_acc: 0.2590\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7630 - acc: 0.2643 - val_loss: 1.7617 - val_acc: 0.2590\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7538 - acc: 0.2786 - val_loss: 1.7556 - val_acc: 0.2590\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7458 - acc: 0.2679 - val_loss: 1.7489 - val_acc: 0.3022\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7296 - acc: 0.2857 - val_loss: 1.7433 - val_acc: 0.3453\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7369 - acc: 0.2536 - val_loss: 1.7381 - val_acc: 0.2734\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7343 - acc: 0.2786 - val_loss: 1.7352 - val_acc: 0.2446\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7454 - acc: 0.2107 - val_loss: 1.7308 - val_acc: 0.2590\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7135 - acc: 0.2929 - val_loss: 1.7256 - val_acc: 0.2950\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7185 - acc: 0.2929 - val_loss: 1.7196 - val_acc: 0.3309\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7064 - acc: 0.2821 - val_loss: 1.7143 - val_acc: 0.3237\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7007 - acc: 0.3000 - val_loss: 1.7126 - val_acc: 0.3165\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.7011 - acc: 0.2857 - val_loss: 1.7044 - val_acc: 0.3165\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.6615 - acc: 0.3786 - val_loss: 1.6931 - val_acc: 0.3453\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.6713 - acc: 0.3643 - val_loss: 1.6880 - val_acc: 0.3453\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.6706 - acc: 0.3357 - val_loss: 1.6822 - val_acc: 0.3453\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.6621 - acc: 0.3750 - val_loss: 1.6711 - val_acc: 0.3381\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.6496 - acc: 0.3893 - val_loss: 1.6598 - val_acc: 0.3381\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.6462 - acc: 0.3679 - val_loss: 1.6506 - val_acc: 0.3453\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.6132 - acc: 0.3964 - val_loss: 1.6445 - val_acc: 0.3453\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.5997 - acc: 0.4143 - val_loss: 1.6388 - val_acc: 0.3309\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.6260 - acc: 0.3714 - val_loss: 1.6262 - val_acc: 0.3237\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.6095 - acc: 0.3964 - val_loss: 1.6106 - val_acc: 0.3525\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.5833 - acc: 0.4536 - val_loss: 1.6014 - val_acc: 0.3813\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.5740 - acc: 0.4036 - val_loss: 1.5924 - val_acc: 0.3669\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.5818 - acc: 0.4071 - val_loss: 1.5911 - val_acc: 0.3669\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.5858 - acc: 0.3821 - val_loss: 1.5956 - val_acc: 0.3453\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.5623 - acc: 0.4143 - val_loss: 1.5761 - val_acc: 0.3741\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.5160 - acc: 0.4786 - val_loss: 1.5556 - val_acc: 0.3885\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.5190 - acc: 0.4393 - val_loss: 1.5380 - val_acc: 0.3885\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.5290 - acc: 0.4679 - val_loss: 1.5259 - val_acc: 0.4029\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.5328 - acc: 0.4179 - val_loss: 1.5157 - val_acc: 0.4317\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.5135 - acc: 0.4643 - val_loss: 1.5033 - val_acc: 0.4029\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.4938 - acc: 0.4607 - val_loss: 1.5007 - val_acc: 0.4101\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.5253 - acc: 0.4286 - val_loss: 1.4867 - val_acc: 0.4532\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.4929 - acc: 0.4643 - val_loss: 1.4836 - val_acc: 0.4460\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.4747 - acc: 0.4857 - val_loss: 1.4759 - val_acc: 0.4676\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.4387 - acc: 0.4821 - val_loss: 1.4830 - val_acc: 0.4173\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.4348 - acc: 0.5000 - val_loss: 1.4570 - val_acc: 0.4604\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.4462 - acc: 0.4893 - val_loss: 1.4435 - val_acc: 0.4748\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.4689 - acc: 0.4893 - val_loss: 1.4376 - val_acc: 0.4604\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.4317 - acc: 0.5357 - val_loss: 1.4382 - val_acc: 0.4532\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.4381 - acc: 0.4750 - val_loss: 1.4199 - val_acc: 0.4748\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.3882 - acc: 0.5286 - val_loss: 1.4109 - val_acc: 0.4676\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit_generator(\n",
    "    generator = trainset, \n",
    "    validation_data = validset, \n",
    "    epochs=50, \n",
    "    callbacks=[early_stopping],\n",
    "    verbose = 1,\n",
    "    use_multiprocessing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c116156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5dad571",
   "metadata": {},
   "source": [
    "### Let's try the same model with numpy arrays and change y with One Hot Encoding to implement in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0394b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's use a bigger dataset for training.\n",
    "\n",
    "images = np.concatenate((images_tr,images_val), axis=0, out=None) \n",
    "y = np.concatenate((y_tr,y_val), axis=0, out=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4cc177e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419, 6)\n",
      "(280, 6)\n",
      "(139, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder as ohe\n",
    "\n",
    "nominal_transformer = ohe(handle_unknown='ignore', sparse = False)\n",
    "\n",
    "y_ohe = nominal_transformer.fit_transform(y.reshape(-1,1))\n",
    "print(y_ohe.shape)\n",
    "\n",
    "\n",
    "y_tr_ohe = nominal_transformer.transform(y_tr.reshape(-1,1))\n",
    "print(y_tr_ohe.shape)\n",
    "\n",
    "y_val_ohe = nominal_transformer.transform(y_val.reshape(-1,1))\n",
    "print(y_val_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce35dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5fdcce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 99, 99, 128)       9728      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 49, 49, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 24, 24, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 16)          4112      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 870       \n",
      "=================================================================\n",
      "Total params: 88,502\n",
      "Trainable params: 88,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model2.add(keras.layers.Conv2D(filters=128, kernel_size=5, strides=3, activation='relu', input_shape=(299, 299, 3)))\n",
    "\n",
    "model2.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "\n",
    "model2.add(keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='relu'))\n",
    "\n",
    "model2.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "\n",
    "model2.add(keras.layers.Conv2D(filters=16, kernel_size=2, strides=2, activation='relu'))\n",
    "\n",
    "model2.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "\n",
    "model2.add(keras.layers.Flatten())\n",
    "model2.add(Dropout(rate=0.3)) # because of overfitting\n",
    "\n",
    "model2.add(keras.layers.Dense(units=trainset.num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47023ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model2.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['acc']) # loss = sparse_categorical_crossentropy does not need OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01d08336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280 samples, validate on 139 samples\n",
      "Epoch 1/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 1.7832 - acc: 0.2000 - val_loss: 1.7514 - val_acc: 0.2446\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 5s 19ms/step - loss: 1.7586 - acc: 0.2393 - val_loss: 1.7516 - val_acc: 0.2518\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 5s 19ms/step - loss: 1.7516 - acc: 0.2857 - val_loss: 1.7432 - val_acc: 0.3165\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 5s 19ms/step - loss: 1.7377 - acc: 0.2857 - val_loss: 1.7332 - val_acc: 0.3094\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 5s 19ms/step - loss: 1.7404 - acc: 0.2679 - val_loss: 1.7317 - val_acc: 0.2734\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 5s 19ms/step - loss: 1.7242 - acc: 0.2893 - val_loss: 1.7253 - val_acc: 0.2878\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 5s 19ms/step - loss: 1.7032 - acc: 0.3214 - val_loss: 1.7205 - val_acc: 0.2734\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 1.6918 - acc: 0.3286 - val_loss: 1.7103 - val_acc: 0.2950\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 1.6793 - acc: 0.3393 - val_loss: 1.7034 - val_acc: 0.3165\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 1.6474 - acc: 0.3464 - val_loss: 1.6983 - val_acc: 0.3381\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 1.6439 - acc: 0.3357 - val_loss: 1.6792 - val_acc: 0.3309\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 1.6194 - acc: 0.3607 - val_loss: 1.6644 - val_acc: 0.3813\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 1.6133 - acc: 0.4036 - val_loss: 1.6712 - val_acc: 0.3165\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 6s 21ms/step - loss: 1.6207 - acc: 0.3643 - val_loss: 1.6443 - val_acc: 0.3165\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 6s 21ms/step - loss: 1.5358 - acc: 0.4071 - val_loss: 1.6243 - val_acc: 0.3885\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 6s 21ms/step - loss: 1.5199 - acc: 0.4250 - val_loss: 1.6076 - val_acc: 0.3741\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 6s 21ms/step - loss: 1.4846 - acc: 0.4679 - val_loss: 1.5825 - val_acc: 0.4029\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 6s 21ms/step - loss: 1.4173 - acc: 0.4893 - val_loss: 1.5740 - val_acc: 0.3885\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 1.3670 - acc: 0.5000 - val_loss: 1.5329 - val_acc: 0.3957\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 1.3808 - acc: 0.5036 - val_loss: 1.5220 - val_acc: 0.4101\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 6s 21ms/step - loss: 1.2900 - acc: 0.5179 - val_loss: 1.5123 - val_acc: 0.4245\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 6s 21ms/step - loss: 1.2175 - acc: 0.5500 - val_loss: 1.4858 - val_acc: 0.4173\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 1.1410 - acc: 0.5679 - val_loss: 1.4546 - val_acc: 0.4604\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 6s 21ms/step - loss: 1.1083 - acc: 0.5679 - val_loss: 1.4673 - val_acc: 0.4101\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 1.0612 - acc: 0.6071 - val_loss: 1.4482 - val_acc: 0.4388\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 6s 21ms/step - loss: 0.9996 - acc: 0.6393 - val_loss: 1.4475 - val_acc: 0.4388\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 1.0863 - acc: 0.5929 - val_loss: 1.4238 - val_acc: 0.4892\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 6s 21ms/step - loss: 1.0753 - acc: 0.5750 - val_loss: 1.4275 - val_acc: 0.4460\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 6s 21ms/step - loss: 0.9052 - acc: 0.6750 - val_loss: 1.4664 - val_acc: 0.4245\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - 6s 21ms/step - loss: 0.9095 - acc: 0.6464 - val_loss: 1.4438 - val_acc: 0.4604\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - 6s 21ms/step - loss: 0.8893 - acc: 0.6714 - val_loss: 1.4214 - val_acc: 0.4173\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 6s 21ms/step - loss: 0.8950 - acc: 0.6821 - val_loss: 1.4411 - val_acc: 0.4173\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 6s 21ms/step - loss: 0.8440 - acc: 0.7000 - val_loss: 1.4321 - val_acc: 0.4676\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 0.8482 - acc: 0.7036 - val_loss: 1.4108 - val_acc: 0.4388\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 0.7675 - acc: 0.7143 - val_loss: 1.4175 - val_acc: 0.4604\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 0.6842 - acc: 0.7643 - val_loss: 1.3888 - val_acc: 0.4964\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 0.7355 - acc: 0.7179 - val_loss: 1.4255 - val_acc: 0.4460\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 0.7290 - acc: 0.7393 - val_loss: 1.4189 - val_acc: 0.4748\n",
      "Epoch 39/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 0.6754 - acc: 0.7679 - val_loss: 1.4494 - val_acc: 0.4892\n",
      "Epoch 40/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 0.5663 - acc: 0.7964 - val_loss: 1.4028 - val_acc: 0.4748\n",
      "Epoch 41/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 0.5468 - acc: 0.8071 - val_loss: 1.5280 - val_acc: 0.4748\n",
      "Epoch 42/50\n",
      "280/280 [==============================] - 6s 20ms/step - loss: 0.6087 - acc: 0.7893 - val_loss: 1.4059 - val_acc: 0.5036\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train model\n",
    "history2 = model2.fit(\n",
    "    x = images_tr, \n",
    "    y = y_tr_ohe, \n",
    "    epochs=50,\n",
    "    validation_data = (images_val,y_val_ohe),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose = 1,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f8992e",
   "metadata": {},
   "source": [
    "Eventually, after several different architectures and trials, I always have a threshold of accuracy around 55% maximum. That is a lot worse than what we have with the high-level features.\n",
    "\n",
    "Considering the low number of images my model is training on (~400) and the fact that it is not a binary prediction but we have 6 outputs possible. I consider 55% to be not that bad. \n",
    "\n",
    "Indeed high-level features from Inception v3 are trained on millions of images\n",
    "\n",
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
