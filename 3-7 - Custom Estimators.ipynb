{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e5bb80",
   "metadata": {},
   "source": [
    "# Custom estimators\n",
    "\n",
    "### This unit is optional\n",
    "In the last unit, we saw how to define our own transformers. In this unit, we will see how to implement custom estimators with the scenario of outliers removal.\n",
    "\n",
    "### Use case - outliers removal\n",
    "Let's start by loading the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6578d9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>484</td>\n",
       "      <td>528275070</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8795</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2586</td>\n",
       "      <td>535305120</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10170</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2289</td>\n",
       "      <td>923228250</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142</td>\n",
       "      <td>535152150</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10552</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>165500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2042</td>\n",
       "      <td>903475060</td>\n",
       "      <td>190</td>\n",
       "      <td>RM</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0    484  528275070           60        RL           NaN      8795   Pave   \n",
       "1   2586  535305120           20        RL          75.0     10170   Pave   \n",
       "2   2289  923228250          160        RM          21.0      2001   Pave   \n",
       "3    142  535152150           20        RL          70.0     10552   Pave   \n",
       "4   2042  903475060          190        RM          60.0     10120   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n",
       "0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
       "1   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
       "2   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
       "3   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
       "4   NaN       IR1          Bnk  ...         0     NaN  MnPrv          NaN   \n",
       "\n",
       "  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
       "0        0       4    2009       WD           Normal     236000  \n",
       "1        0       6    2006       WD           Normal     155000  \n",
       "2        0       1    2007       WD           Normal      75000  \n",
       "3        0       4    2010       WD           Normal     165500  \n",
       "4        0       1    2007       WD           Normal     122000  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_df = pd.read_csv('house-prices.csv')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be842b2b",
   "metadata": {},
   "source": [
    "We learned about skewed distributions in the last subject and saw how log-transforms can help in such cases. However, it's still possible that some values remain far from the mean after the transformation.\n",
    "\n",
    "For instance, let's plot the z-scores distribution of the Lot Area variable before and after the log-transform. This time, we use the zscore() function from the scipy.stats module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66009b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "\n",
    "# Check for outliers in the continuous features\n",
    "c = 'Lot Area'\n",
    "x = data_df[c].dropna()\n",
    "\n",
    "# Plot histograms\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))\n",
    "ax1.hist(zscore(x), bins=50)\n",
    "ax2.hist(zscore(np.log1p(x)), bins=50)\n",
    "ax1.set_title(c)\n",
    "ax2.set_title('log({})'.format(c))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf3f49",
   "metadata": {},
   "source": [
    "We can see that the transformation helps, but there are still many values with a z-score above +3 or below -3. We could simply remove them with Pandas before applying our ML models in Scikit-learn. However, let's see how to encapsulate this preprocessing step into a Scikit-learn object.\n",
    "\n",
    "The Lot Area isn't the only variable with a skewed distribution in this data set. In the following code, we list them and create the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe3d2980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Garage Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>20896</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2077.0</td>\n",
       "      <td>2097</td>\n",
       "      <td>1134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>8930</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1902</td>\n",
       "      <td>539.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>3811</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>1646</td>\n",
       "      <td>482.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>11200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>1298</td>\n",
       "      <td>403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>31250</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lot Area  Lot Frontage  Total Bsmt SF  Gr Liv Area  Garage Area\n",
       "339      20896          49.0         2077.0         2097       1134.0\n",
       "1557      8930          68.0            0.0         1902        539.0\n",
       "2167      3811          44.0         1594.0         1646        482.0\n",
       "706      11200           NaN         1298.0         1298        403.0\n",
       "2396     31250         125.0            0.0         1600        270.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create X, y\n",
    "X = data_df.drop('SalePrice', axis=1)\n",
    "y = np.log10(data_df.SalePrice)\n",
    "\n",
    "# Split into train/test sets\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Continuous variables to check\n",
    "to_check = ['Lot Area', 'Lot Frontage', 'Total Bsmt SF', 'Gr Liv Area', 'Garage Area']\n",
    "X_tr[to_check].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec2c89c",
   "metadata": {},
   "source": [
    "Note that we still have missing values in the data. In this unit, we ignore them during the outliers removal part and will then see later in this unit how to replace them using a SimpleImputer transformer object.\n",
    "\n",
    "### ClassifierMixin object\n",
    "In the last unit, we defined our own transformers by creating a subclass of the BaseEstimator and TransformerMixin. Similarly, we can define **custom estimators** by creating a subclass of BaseEstimator and\n",
    "\n",
    "- RegressorMixin for **regression** tasks\n",
    "- ClassifierMixin for **classification** ones\n",
    "\n",
    "Let's see how to create a ZScoresOutlierClassifier class that takes a set of column names to check for outliers and a removal threshold. This custom estimator will predict whether a point is an outlier or not - since this is a classification task, we need to extend ClassifierMixin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72bd21eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# Custom outliers detector base on z-scores\n",
    "# Adapted from https://github.com/scikit-learn/scikit-learn/issues/9630#issuecomment-325202441\n",
    "class ZScoresOutlierClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, columns, threshold=3):\n",
    "        self.columns = columns\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X_df, y):\n",
    "        # Check that X_df is a DataFrame\n",
    "        assert type(X_df) == pd.DataFrame\n",
    "\n",
    "        # Compute train mean/std\n",
    "        self.train_mean_ = X_df[self.columns].mean()\n",
    "        self.train_std_ = X_df[self.columns].std()\n",
    "\n",
    "        # Return estimator\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_df):\n",
    "        # Check that X_df is a DataFrame\n",
    "        assert type(X_df) == pd.DataFrame\n",
    "\n",
    "        # Apply threshold\n",
    "        z_scores = (X_df[self.columns] - self.train_mean_) / (self.train_std_)\n",
    "        below_threshold = np.abs(z_scores.fillna(0)) <= self.threshold\n",
    "\n",
    "        # Find inliners\n",
    "        mask = below_threshold.all(axis=1)\n",
    "\n",
    "        # Return predictions: +1 for inliners, -1 for outliers\n",
    "        return mask.replace({True: 1, False: -1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05959296",
   "metadata": {},
   "source": [
    "In this code, we define two functions: fit() and predict().\n",
    "\n",
    "The fit function computes the mean and standard deviation of each column of the train DataFrame and stores them in the train_mean_ and train_std_ variables. The \"predict\" part computes the z-scores using simple Pandas code and checks that the data points are below the defined threshold.\n",
    "\n",
    "Note the Pandas all(axis=1) call - a point that isn't an outlier should have all its z-scores below the threshold. Finally, we return 1 for normal points and -1 for outliers: this is the standard encoding for outlier detector objects from Scikit-learn.\n",
    "\n",
    "Let's test our custom classifier on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c3ee739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339    -1\n",
       "1557    1\n",
       "2167    1\n",
       "706     1\n",
       "2396    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_clf = ZScoresOutlierClassifier(to_check)\n",
    "outliers_clf.fit(X_tr, y_tr)\n",
    "outliers_clf.predict(X_tr).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eaa093",
   "metadata": {},
   "source": [
    "### RegressorMixin object\n",
    "Now that we have a custom outlier classifier, let's see how to use it to improve our predictions. Remember: outliers hurt the performance of our models because of the RSS-based cost functions which have bad statistical properties i.e. they don't handle well statistically extreme values.\n",
    "\n",
    "Let's define a WithoutOutliersRegressor object that first removes the outliers from the training data before fitting the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b6bbf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import RegressorMixin, clone\n",
    "\n",
    "# Custom regressor with an embedded outliers detector\n",
    "# Adapted from https://github.com/scikit-learn/scikit-learn/issues/9630#issuecomment-325202441\n",
    "class WithoutOutliersRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, outlier_detector, regressor):\n",
    "        self.outlier_detector = outlier_detector\n",
    "        self.regressor = regressor\n",
    "\n",
    "    def fit(self, X, y, verbose=False):\n",
    "        # Fit outliers detector, use it on X\n",
    "        self.outlier_detector_ = clone(self.outlier_detector).fit(X, y)\n",
    "        outliers = self.outlier_detector_.predict(X) == -1\n",
    "\n",
    "        # Print the number of outliers detected\n",
    "        if verbose:\n",
    "            print('Outliers detected: {} ({:.1f}%)'.format(\n",
    "                outliers.sum(), 100*outliers.mean()))\n",
    "\n",
    "        # Fit regressor without the outliers\n",
    "        self.regressor_ = clone(self.regressor).fit(X[~outliers], y[~outliers])\n",
    "\n",
    "        # Return the estimator\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions with the regressor (fitted without the outliers)\n",
    "        return self.regressor_.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff46a87d",
   "metadata": {},
   "source": [
    "Again, we need to define the fit() and predict() functions.\n",
    "\n",
    "In the fit part, we fit our outlier detector to the training data, create an outliers mask and use it to exclude outliers from our model fit() call. In the \"predict\" part, we simply use our fitted regressor object to make new predictions for all data points i.e. including potential outliers.\n",
    "\n",
    "So far in this course, we always saw examples where the current state of our estimators was clear ex. is it fitted, on what data are the coefficients computed and so on. However, in this implementation, we are working with an outlier detector and a regressor that are created outside our custom estimator, and we modify them inside it by calling the .fit() method.\n",
    "\n",
    "To avoid any confusion, we clone the estimators with the clone() function from Scikit-learn - that way, we are sure to leave the original objects unmodified. This issue is very similar to what can happen with Pandas inplace=True operations. If you're curious about this, you can take a look at this example which illustrate the issue.\n",
    "\n",
    "https://stackoverflow.com/q/13701603/3890306\n",
    "\n",
    "### Complete pipeline\n",
    "Let's use our new estimator in a complete pipeline. First, we need to fill missing values and encode non-numerical variables. This time, we will use the SimpleImputer object from Scikit-learn to handle missing values.\n",
    "\n",
    "By setting its strategy parameter to most_frequent, the imputer simply replaces missing values with the most frequent value found in the column. Other possible strategies are mean, median and constant. You can always refer to the documentation if you're unsure about the different options.\n",
    "\n",
    "Let's also define the transformations for the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a52a3afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-hot encoding for non-numerical columns\n",
    "onehot_columns = X.select_dtypes(exclude=np.number).columns\n",
    "onehot_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3826b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Basic transformations for the others\n",
    "other_columns = X.columns.difference(onehot_columns)\n",
    "other_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('log', FunctionTransformer(np.log1p)),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "250c1d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('onehot', onehot_transformer, onehot_columns),\n",
    "    ('other', other_transformer, other_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78ef7b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Define pipeline\n",
    "model = WithoutOutliersRegressor(\n",
    "    outlier_detector=ZScoresOutlierClassifier(to_check, threshold=3),\n",
    "    regressor=Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('ridge', Ridge())\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbb0048",
   "metadata": {},
   "source": [
    "It's important to note that our ZScoresOutlierClassifier works on the untransformed DataFrame - our preprocessor is only applied before the Ridge model! For this reason, the detector is working on the original variables and not the log-transformed ones.\n",
    "\n",
    "To apply the outliers detector on the log-transformed variables, we cannot simply encapsulate our detector into a ColumnTransformer that applies the log-transform to the columns listed in to_check. The reason is simple: as we saw in the last units, column transformer objects produce Numpy arrays. However, our outliers detector works on DataFrames!\n",
    "\n",
    "**Challenge:** Can you adjust the ZScoresOutlierClassifier to accept Numpy arrays instead of Pandas DataFrames to make it fully compatible with Scikit-learn objects?\n",
    "\n",
    "### Final evaluation\n",
    "Let's see how our fully-encapsulated model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69e434d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected: 38 (3.1%)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "model.fit(X_tr, y_tr, verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359dac4c",
   "metadata": {},
   "source": [
    "The outlier detector labeled around 3% of the entries as outliers. Those training points won't be used to fit the model.\n",
    "\n",
    "Let's evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f4d2dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 14,220$\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "# Evaluate predictions\n",
    "y_pred = model.predict(X_te)\n",
    "print('MAE: {:,.0f}$'.format(MAE(10**y_te, 10**y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce27f1d",
   "metadata": {},
   "source": [
    "This time, we get an MAE score around 14 thousand dollars which is similar to what we obtained in the previous units.\n",
    "\n",
    "The advantage of our pipeline is that we can easily switch to other outlier detection methods. It's not part of the course to know how the different detectors work, but it's important to know that Scikit-learn implements many advanced techniques that can be used out-of-the-box once we are familiar with the **transformers and estimators API.**\n",
    "\n",
    "The library also does a great job at documenting the different approaches. If you google sklearn outlier detection, you should get this page which documents them in the top results.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/outlier_detection.html#overview-of-outlier-detection-methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a083fc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lyeso\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:417: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected: 122 (10.0%)\n",
      "MAE: 14,442$\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Try with Isolation forests\n",
    "model2 = WithoutOutliersRegressor(\n",
    "    outlier_detector=make_pipeline(\n",
    "        preprocessor, IsolationForest(random_state=0)),\n",
    "    regressor=Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('ridge', Ridge())\n",
    "    ])\n",
    ")\n",
    "model2.fit(X_tr, y_tr, verbose=True)\n",
    "\n",
    "# Evaluate predictions\n",
    "y_pred = model2.predict(X_te)\n",
    "print('MAE: {:,.0f}$'.format(MAE(10**y_te, 10**y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f43543",
   "metadata": {},
   "source": [
    "This time, we add our preprocessor before the IsolationForest using the make_pipeline() function to quickly create a Pipeline without having to name each step.\n",
    "\n",
    "As we can see, the isolation forest labels 10% of the data points as outliers and we get a slightly larger MAE score.\n",
    "\n",
    "### Summary\n",
    "In this unit, we saw how to create custom estimators with the example of outliers removal. Custom estimators can be particularly useful if we need to encapsulate tools from other libraries into our Scikit-learn workflow. **For instance, encapsulate ML methods from NLTK, TensorFlow or even our own algorithms.**\n",
    "\n",
    "In the next unit, we will discuss advanced transformations that can improve the performance of our models. This will end our tour of the Scikit-learn library and machine learning workflow.\n",
    "\n",
    "# Advanced transformations\n",
    "\n",
    "### This unit is optional\n",
    "Transforming a variable to make it more Gaussian-like is a common operation in machine learning. In this unit, we will see different ways to do it with Scikit-learn.\n",
    "\n",
    "We will take the house prices data set as an example and build a simple model with two features: the overall quality of the house and its ground living area.\n",
    "\n",
    "### Target transformation\n",
    "Let's start by loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "954a6fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>484</td>\n",
       "      <td>528275070</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8795</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2586</td>\n",
       "      <td>535305120</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10170</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2289</td>\n",
       "      <td>923228250</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142</td>\n",
       "      <td>535152150</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10552</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>165500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2042</td>\n",
       "      <td>903475060</td>\n",
       "      <td>190</td>\n",
       "      <td>RM</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0    484  528275070           60        RL           NaN      8795   Pave   \n",
       "1   2586  535305120           20        RL          75.0     10170   Pave   \n",
       "2   2289  923228250          160        RM          21.0      2001   Pave   \n",
       "3    142  535152150           20        RL          70.0     10552   Pave   \n",
       "4   2042  903475060          190        RM          60.0     10120   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n",
       "0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
       "1   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
       "2   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
       "3   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
       "4   NaN       IR1          Bnk  ...         0     NaN  MnPrv          NaN   \n",
       "\n",
       "  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
       "0        0       4    2009       WD           Normal     236000  \n",
       "1        0       6    2006       WD           Normal     155000  \n",
       "2        0       1    2007       WD           Normal      75000  \n",
       "3        0       4    2010       WD           Normal     165500  \n",
       "4        0       1    2007       WD           Normal     122000  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_df = pd.read_csv('house-prices.csv')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf6b21c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create X, y\n",
    "X = data_df[['Overall Qual', 'Gr Liv Area']]\n",
    "y = data_df.SalePrice\n",
    "\n",
    "# Split into train/test sets\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e78162b",
   "metadata": {},
   "source": [
    "We already saw that the sale prices have a right-skewed distribution which can make the model biased toward expensive houses. One of the simplest ways to handle this problem is to apply a log-transform.\n",
    "\n",
    "In practice, we don't really want to do this transformation outside Scikit-learn which would imply that we have to manually transform y before calling model.fit() and apply the inverse transformation to predictions after model.predict() calls.\n",
    "\n",
    "To solve this issue, Scikit-learn implements a TransformedTargetRegressor which can automatically apply some transformation to the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "915cf366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "regressor = TransformedTargetRegressor(\n",
    "    regressor=LinearRegression(), func=np.log, inverse_func=np.exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ab50d",
   "metadata": {},
   "source": [
    "The func attribute is the function that we want to apply before fitting the model, and the inverse_func one the inverse operation to transform the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43573418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "regressor.fit(X_tr, y_tr)\n",
    "y_pred = regressor.predict(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb4b71c",
   "metadata": {},
   "source": [
    "In this code, both y_tr and y_pred are prices in dollars - the transformation is done inside our regressor estimator.\n",
    "\n",
    "Let's verify that those two variables have more or less the same distribution. This is an easy way to detect when the model is not working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81e50fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot predictions\n",
    "plt.hist(y_te, bins=50, range=(0, 10**6), density=True, alpha=0.3, label='sale prices')\n",
    "plt.hist(y_pred, bins=50, range=(0, 10**6), density=True, alpha=0.3, label='predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5479af",
   "metadata": {},
   "source": [
    "In this code, the density attribute normalizes the histograms such that they are proper probability distributions that we can compare. We also focus on houses with an observed and estimated price below 1 million by adjusting the range argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eb6b744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 25,412$\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "print('MAE: {:,.0f}$'.format(MAE(y_te, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa7ab2c",
   "metadata": {},
   "source": [
    "On average, our predictions are around 25 thousand dollars away from the observed price.\n",
    "\n",
    "### Other transformations\n",
    "The log-transform works really well when the variables have a skewed distribution. **More generally, there are several approaches to make a variable distribution more Gaussian-like.** It's out of the scope of this course to understand them in details, but **it's important to know that we can easily try them since we're now familiar with the transformer API.**\n",
    "\n",
    "or instance, let's try the QuantileTransformer one on the sale prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df47ffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 24,728$\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "regressor = TransformedTargetRegressor(\n",
    "    regressor=LinearRegression(),\n",
    "    transformer=QuantileTransformer(output_distribution='normal', random_state=0))\n",
    "regressor.fit(X_tr, y_tr)\n",
    "print('MAE: {:,.0f}$'.format(MAE(y_te, regressor.predict(X_te))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d581995",
   "metadata": {},
   "source": [
    "Let's also try adding the PowerTransformer one to the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6c8de84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 24,410$\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "regressor = TransformedTargetRegressor(\n",
    "    regressor=make_pipeline(PowerTransformer(), LinearRegression()),\n",
    "    transformer=QuantileTransformer(output_distribution='normal', random_state=0))\n",
    "regressor.fit(X_tr, y_tr)\n",
    "print('MAE: {:,.0f}$'.format(MAE(y_te, regressor.predict(X_te)))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9e8bd7",
   "metadata": {},
   "source": [
    "Again, we improved a bit the MAE which is now 24,410 dollars.\n",
    "\n",
    "To get a more exhaustive list of the preprocessing steps available in Scikit-learn, make sure to take a look at the Preprocessing Guide from the official website.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac2dbda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
