{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fc10823",
   "metadata": {},
   "source": [
    "# Convolutional Networks\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca5121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn as skl\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"-1\" # Force Tensorflow on CPU instead of GPU (seems to avoid an error with my CUDA compatible GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d462a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data form NPZ file\n",
    "\n",
    "train_data = \"train.npz\"\n",
    "X_tr = np.load(train_data)[\"features\"]\n",
    "y_tr = np.load(train_data)[\"labels\"]\n",
    "images_tr = np.load(train_data)[\"pixels\"]\n",
    "names_tr = np.load(train_data)[\"names\"]\n",
    "\n",
    "valid_data = \"valid.npz\"\n",
    "X_val= np.load(valid_data)[\"features\"]\n",
    "y_val = np.load(valid_data)[\"labels\"]\n",
    "images_val = np.load(valid_data)[\"pixels\"]\n",
    "names_val = np.load(valid_data)[\"names\"]\n",
    "\n",
    "test_data = \"test.npz\"\n",
    "X_te= np.load(test_data)[\"features\"]\n",
    "y_te = np.load(test_data)[\"labels\"]\n",
    "images_te = np.load(test_data)[\"pixels\"]\n",
    "names_te = np.load(test_data)[\"names\"]\n",
    "\n",
    "# Create a dictionnary for labels\n",
    "labels_dict = {0: 'bike', 1 : 'car', 2: 'motorcycle', 3: 'other', 4:'truck', 5: 'van'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d061ee9",
   "metadata": {},
   "source": [
    "### Let's use the train generator to have more images to train on and use in the Convolutional Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ac1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image generator\n",
    "train_generator = ImageDataGenerator(rescale=1/255, rotation_range = 10, horizontal_flip = True, vertical_flip = False, zoom_range = 0.2)\n",
    "test_generator = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ed221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validation and test sets\n",
    "\n",
    "\n",
    "# class_mode = categorical to have a one hot encoded \"y\" output.\n",
    "\n",
    "trainset = train_generator.flow_from_directory(\n",
    "    os.path.join('Course Project - SwissRoads', 'train'), batch_size =500, target_size=(299, 299),\n",
    "    shuffle=True, color_mode='rgb', class_mode = 'categorical') \n",
    "\n",
    "validset = test_generator.flow_from_directory(\n",
    "    os.path.join('Course Project - SwissRoads', 'valid'),batch_size =500, target_size=(299, 299),\n",
    "    shuffle=False, color_mode='rgb', class_mode = 'categorical')\n",
    "testset = test_generator.flow_from_directory(\n",
    "    os.path.join('Course Project - SwissRoads', 'test'),batch_size =500, target_size=(299, 299),\n",
    "    shuffle=False,color_mode='rgb', class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407dab44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9ce40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f643e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e645a2e3",
   "metadata": {},
   "source": [
    "### Let's create a 2 layers convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad924d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57730761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6186e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Network\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=128, kernel_size=5, strides=2,\n",
    "                              activation='relu', input_shape=(299, 299, 3)))\n",
    "\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=3, strides=1,\n",
    "                              activation='relu'))\n",
    "\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(Dropout(rate=0.5)) # because of overfitting\n",
    "\n",
    "model.add(keras.layers.Dense(units=trainset.num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3f28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac092745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End training when accuracy stops improving (optional)\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit_generator(\n",
    "    generator = trainset, \n",
    "    validation_data = validset, \n",
    "    epochs=50, \n",
    "    callbacks=[early_stopping],\n",
    "    verbose = 1,\n",
    "    use_multiprocessing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf6efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c226131",
   "metadata": {},
   "source": [
    "### Let's try the same model with numpy arrays and change y with One Hot Encoding to implement in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d40ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's use a bigger dataset for training.\n",
    "\n",
    "images = np.concatenate((images_tr,images_val), axis=0, out=None) \n",
    "y = np.concatenate((y_tr,y_val), axis=0, out=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b58fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder as ohe\n",
    "\n",
    "nominal_transformer = ohe(handle_unknown='ignore', sparse = False)\n",
    "\n",
    "y_ohe = nominal_transformer.fit_transform(y.reshape(-1,1))\n",
    "print(y_ohe.shape)\n",
    "\n",
    "\n",
    "y_tr_ohe = nominal_transformer.fit_transform(y_tr.reshape(-1,1))\n",
    "print(y_tr_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33035c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_ohe[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9475869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential()\n",
    "\n",
    "\n",
    "model2.add(keras.layers.Conv2D(filters=128, kernel_size=5, strides=2,\n",
    "                              activation='relu', input_shape=(299, 299, 3)))\n",
    "\n",
    "model2.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "model2.add(keras.layers.Conv2D(filters=32, kernel_size=3, strides=1,\n",
    "                              activation='relu'))\n",
    "\n",
    "model2.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "\n",
    "model2.add(keras.layers.Flatten())\n",
    "\n",
    "model2.add(Dropout(rate=0.5)) # because of overfitting\n",
    "\n",
    "model2.add(keras.layers.Dense(units = len(y_ohe[0]), activation='softmax'))\n",
    "\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model2.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Train model\n",
    "history2 = model2.fit(\n",
    "    x = images, \n",
    "    y = y_ohe, \n",
    "    epochs=50,\n",
    "    validation_split = 0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose = 1,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d36b75d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
